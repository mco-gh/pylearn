{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mco-gh/pylearn/blob/master/notebooks/8_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 8 - Files\n",
        "\n",
        "**Make a copy of this notebook by selecting File->Save a copy in Drive from the menu bar above.**\n",
        "\n",
        "- [Link to this notebook on Colab](https://colab.research.google.com/github/mco-gh/pylearn/blob/master/notebooks/8_Files.ipynb)\n",
        "- [Link to this notebook on Github](https://github.com/mco-gh/pylearn/blob/master/notebooks/8_Files.ipynb)"
      ],
      "metadata": {
        "id": "n0jAgjUsl7lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "title: Analyzing Data from Multiple Files\n",
        "teaching: 20\n",
        "exercises: 0\n",
        "questions:\n",
        "- \"How can I do the same operations on many different files?\"\n",
        "objectives:\n",
        "- \"Use a library function to get a list of filenames that match a wildcard pattern.\"\n",
        "- \"Write a `for` loop to process multiple files.\"\n",
        "keypoints:\n",
        "- \"Use `glob.glob(pattern)` to create a list of files whose names match a pattern.\"\n",
        "- \"Use `*` in a pattern to match zero or more characters, and `?` to match any single character.\"\n",
        "---\n",
        "\n",
        "As a final piece to processing our inflammation data, we need a way to get a list of all the files\n",
        "in our `data` directory whose names start with `inflammation-` and end with `.csv`.\n",
        "The following library will help us to achieve this:\n",
        "~~~\n",
        "import glob\n",
        "~~~\n",
        "{: .language-python}\n",
        "\n",
        "The `glob` library contains a function, also called `glob`,\n",
        "that finds files and directories whose names match a pattern.\n",
        "We provide those patterns as strings:\n",
        "the character `*` matches zero or more characters,\n",
        "while `?` matches any one character.\n",
        "We can use this to get the names of all the CSV files in the current directory:\n",
        "\n",
        "~~~\n",
        "print(glob.glob('inflammation*.csv'))\n",
        "~~~\n",
        "{: .language-python}\n",
        "\n",
        "~~~\n",
        "['inflammation-05.csv', 'inflammation-11.csv', 'inflammation-12.csv', 'inflammation-08.csv',\n",
        "'inflammation-03.csv', 'inflammation-06.csv', 'inflammation-09.csv', 'inflammation-07.csv',\n",
        "'inflammation-10.csv', 'inflammation-02.csv', 'inflammation-04.csv', 'inflammation-01.csv']\n",
        "~~~\n",
        "{: .output}\n",
        "\n",
        "As these examples show,\n",
        "`glob.glob`'s result is a list of file and directory paths in arbitrary order.\n",
        "This means we can loop over it\n",
        "to do something with each filename in turn.\n",
        "In our case,\n",
        "the \"something\" we want to do is generate a set of plots for each file in our inflammation dataset.\n",
        "\n",
        "If we want to start by analyzing just the first three files in alphabetical order, we can use the\n",
        "`sorted` built-in function to generate a new sorted list from the `glob.glob` output:\n",
        "\n",
        "~~~\n",
        "import glob\n",
        "import numpy\n",
        "import matplotlib.pyplot\n",
        "\n",
        "filenames = sorted(glob.glob('inflammation*.csv'))\n",
        "filenames = filenames[0:3]\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "\n",
        "    data = numpy.loadtxt(fname=filename, delimiter=',')\n",
        "\n",
        "    fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
        "\n",
        "    axes1 = fig.add_subplot(1, 3, 1)\n",
        "    axes2 = fig.add_subplot(1, 3, 2)\n",
        "    axes3 = fig.add_subplot(1, 3, 3)\n",
        "\n",
        "    axes1.set_ylabel('average')\n",
        "    axes1.plot(numpy.mean(data, axis=0))\n",
        "\n",
        "    axes2.set_ylabel('max')\n",
        "    axes2.plot(numpy.max(data, axis=0))\n",
        "\n",
        "    axes3.set_ylabel('min')\n",
        "    axes3.plot(numpy.min(data, axis=0))\n",
        "\n",
        "    fig.tight_layout()\n",
        "    matplotlib.pyplot.show()\n",
        "~~~\n",
        "{: .language-python}\n",
        "\n",
        "~~~\n",
        "inflammation-01.csv\n",
        "~~~\n",
        "{: .output}\n",
        "\n",
        "![Output from the first iteration of the for loop. Three line graphs showing the daily average,\n",
        "maximum and minimum inflammation over a 40-day period for all patients in the first dataset.](\n",
        "https://github.com/mco-gh/pylearn/blob/master/fig/03-loop_49_1.png?raw=1)\n",
        "\n",
        "~~~\n",
        "inflammation-02.csv\n",
        "~~~\n",
        "{: .output}\n",
        "\n",
        "![Output from the second iteration of the for loop. Three line graphs showing the daily average,\n",
        "maximum and minimum inflammation over a 40-day period for all patients in the second\n",
        "dataset.](https://github.com/mco-gh/pylearn/blob/master/fig/03-loop_49_3.png?raw=1)\n",
        "\n",
        "~~~\n",
        "inflammation-03.csv\n",
        "~~~\n",
        "{: .output}\n",
        "\n",
        "![Output from the third iteration of the for loop. Three line graphs showing the daily average,\n",
        "maximum and minimum inflammation over a 40-day period for all patients in the third\n",
        "dataset.](https://github.com/mco-gh/pylearn/blob/master/fig/03-loop_49_5.png?raw=1)\n",
        "\n",
        "\n",
        "The plots generated for the second clinical trial file look very similar to the plots for\n",
        "the first file: their average plots show similar \"noisy\" rises and falls; their maxima plots\n",
        "show exactly the same linear rise and fall; and their minima plots show similar staircase\n",
        "structures.\n",
        "\n",
        "The third dataset shows much noisier average and maxima plots that are far less suspicious than\n",
        "the first two datasets, however the minima plot shows that the third dataset minima is\n",
        "consistently zero across every day of the trial. If we produce a heat map for the third data file\n",
        "we see the following:\n",
        "\n",
        "![Heat map of the third inflammation dataset. Note that there are sporadic zero values throughout\n",
        "the entire dataset, and the last patient only has zero values over the 40 day study.\n",
        "](https://github.com/mco-gh/pylearn/blob/master/fig/inflammation-03-imshow.svg?raw=1)\n",
        "\n",
        "We can see that there are zero values sporadically distributed across all patients and days of the\n",
        "clinical trial, suggesting that there were potential issues with data collection throughout the\n",
        "trial. In addition, we can see that the last patient in the study didn't have any inflammation\n",
        "flare-ups at all throughout the trial, suggesting that they may not even suffer from arthritis!\n",
        "\n",
        "\n",
        "> ## Plotting Differences\n",
        ">\n",
        "> Plot the difference between the average inflammations reported in the first and second datasets\n",
        "> (stored in `inflammation-01.csv` and `inflammation-02.csv`, correspondingly),\n",
        "> i.e., the difference between the leftmost plots of the first two figures.\n",
        ">\n",
        "> > ## Solution\n",
        "> > ~~~\n",
        "> > import glob\n",
        "> > import numpy\n",
        "> > import matplotlib.pyplot\n",
        "> >\n",
        "> > filenames = sorted(glob.glob('inflammation*.csv'))\n",
        "> >\n",
        "> > data0 = numpy.loadtxt(fname=filenames[0], delimiter=',')\n",
        "> > data1 = numpy.loadtxt(fname=filenames[1], delimiter=',')\n",
        "> >\n",
        "> > fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
        "> >\n",
        "> > matplotlib.pyplot.ylabel('Difference in average')\n",
        "> > matplotlib.pyplot.plot(numpy.mean(data0, axis=0) - numpy.mean(data1, axis=0))\n",
        "> >\n",
        "> > fig.tight_layout()\n",
        "> > matplotlib.pyplot.show()\n",
        "> > ~~~\n",
        "> > {: .language-python}\n",
        "> {: .solution}\n",
        "{: .challenge}\n",
        "\n",
        "> ## Generate Composite Statistics\n",
        ">\n",
        "> Use each of the files once to generate a dataset containing values averaged over all patients:\n",
        ">\n",
        "> ~~~\n",
        "> filenames = glob.glob('inflammation*.csv')\n",
        "> composite_data = numpy.zeros((60,40))\n",
        "> for filename in filenames:\n",
        ">     # sum each new file's data into composite_data as it's read\n",
        ">     #\n",
        "> # and then divide the composite_data by number of samples\n",
        "> composite_data = composite_data / len(filenames)\n",
        "> ~~~\n",
        "> {: .language-python}\n",
        ">\n",
        "> Then use pyplot to generate average, max, and min for all patients.\n",
        ">\n",
        "> > ## Solution\n",
        "> > ~~~\n",
        "> > import glob\n",
        "> > import numpy\n",
        "> > import matplotlib.pyplot\n",
        "> >\n",
        "> > filenames = glob.glob('inflammation*.csv')\n",
        "> > composite_data = numpy.zeros((60,40))\n",
        "> >\n",
        "> > for filename in filenames:\n",
        "> >     data = numpy.loadtxt(fname = filename, delimiter=',')\n",
        "> >     composite_data = composite_data + data\n",
        "> >\n",
        "> > composite_data = composite_data / len(filenames)\n",
        "> >\n",
        "> > fig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n",
        "> >\n",
        "> > axes1 = fig.add_subplot(1, 3, 1)\n",
        "> > axes2 = fig.add_subplot(1, 3, 2)\n",
        "> > axes3 = fig.add_subplot(1, 3, 3)\n",
        "> >\n",
        "> > axes1.set_ylabel('average')\n",
        "> > axes1.plot(numpy.mean(composite_data, axis=0))\n",
        "> >\n",
        "> > axes2.set_ylabel('max')\n",
        "> > axes2.plot(numpy.max(composite_data, axis=0))\n",
        "> >\n",
        "> > axes3.set_ylabel('min')\n",
        "> > axes3.plot(numpy.min(composite_data, axis=0))\n",
        "> >\n",
        "> > fig.tight_layout()\n",
        "> >\n",
        "> > matplotlib.pyplot.show()\n",
        "> > ~~~\n",
        "> > {: .language-python}\n",
        ">{: .solution}\n",
        "{: .challenge}\n",
        "\n",
        "After spending some time investigating the heat map and statistical plots, as well as\n",
        "doing the above exercises to plot differences between datasets and to generate composite\n",
        "patient statistics, we gain some insight into the twelve clinical trial datasets.\n",
        "\n",
        "The datasets appear to fall into two categories:\n",
        "\n",
        "* seemingly \"ideal\" datasets that agree excellently with Dr. Maverick's claims,\n",
        "  but display suspicious maxima and minima (such as `inflammation-01.csv` and `inflammation-02.csv`)\n",
        "* \"noisy\" datasets that somewhat agree with Dr. Maverick's claims, but show concerning\n",
        "  data collection issues such as sporadic missing values and even an unsuitable candidate\n",
        "  making it into the clinical trial.\n",
        "\n",
        "In fact, it appears that all three of the \"noisy\" datasets (`inflammation-03.csv`,\n",
        "`inflammation-08.csv`, and `inflammation-11.csv`) are identical down to the last value.\n",
        "Armed with this information, we confront Dr. Maverick about the suspicious data and\n",
        "duplicated files.\n",
        "\n",
        "Dr. Maverick confesses that they fabricated the clinical data after they found out\n",
        "that the initial trial suffered from a number of issues, including unreliable data-recording and\n",
        "poor participant selection. They created fake data to prove their drug worked, and when we asked\n",
        "for more data they tried to generate more fake datasets, as well as throwing in the original\n",
        "poor-quality dataset a few times to try and make all the trials seem a bit more \"realistic\".\n",
        "\n",
        "Congratulations! We've investigated the inflammation data and proven that the datasets have been\n",
        "synthetically generated.\n",
        "\n",
        "But it would be a shame to throw away the synthetic datasets that have taught us so much\n",
        "already, so we'll forgive the imaginary Dr. Maverick and continue to use the data to learn\n",
        "how to program.\n",
        "\n",
        "{% include links.md %}\n"
      ],
      "metadata": {
        "id": "Ar4XXhWkuMiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Previous Lesson](https://mco.fyi/py5)\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "[Next Lesson](https://mco.fyi/py7)"
      ],
      "metadata": {
        "id": "UgSxVhDyPg10"
      }
    }
  ]
}